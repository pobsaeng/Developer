{"sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionService":{"messages":["No Spark job batch id is returned from response.{0}[Error] {1}","No log is returned within response.{0}[Error] {1}"],"keys":["sparkJobSubmission_LivyNoBatchIdReturned","sparkJobSubmission_LivyNoLogReturned"]},"sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionModel":{"messages":["Parameters for SparkJobSubmissionModel is illegal","submissionArgs is invalid. ","submissionArgs is invalid. ","livyBatchId is invalid. ","Get Application Id time out. {0}[Log]   {1}","Property localFilePath or hdfsFolderPath is not specified. ","Property Path is not specified. "],"keys":["sparkJobSubmission_SparkJobSubmissionModelInitializeError","sparkJobSubmission_submissionArgsIsInvalid","sparkJobSubmission_submissionArgsIsInvalid","sparkJobSubmission_LivyBatchIdIsInvalid","sparkJobSubmission_GetApplicationIdTimeOut","sparkJobSubmission_localFileOrFolderNotSpecified.","sparkJobSubmission_PathNotSpecified."]},"sparkFeature/dialog/sparkJobSubmission/sparkJobSubmissionDialog":{"messages":["Parameters for SparkJobSubmissionDialog is illegal","New Job","Cancel","Submit","{0} Spark Job Submission:",".......................... Submit Spark Job Start .........................."],"keys":["sparkJobSubmission_SparkJobSubmissionDialogInitializeError","sparkJobSubmission_DialogTitleNewJob","sparkJobSubmission_DialogCancelButton","sparkJobSubmission_DialogSubmitButton","sparkJobSubmission_SubmitSparkJob","sparkJobSubmission_SubmissionStartMessage"]},"sparkFeature/dialog/sparkJobSubmission/sparkConfigurationTab":{"messages":["GENERAL","Enter a name ...","Job Name","Spark Cluster","Path to a .jar or .py file","The selected local file will be uploaded to HDFS: {0}","JAR/py File","Main Class","Arguments","Command line arguments used in your main class, multiple arguments should be split by space.","Property Job Name is not specified.","Property JAR/py File is not specified.","Property JAR/py File is not specified.","Property Main Class is not specified.","{0} does not exist in Cluster or exception thrown. ","The specified HDFS file does not exist. ","Select","Error in locating the file due to Error: {0}"],"keys":["sparkJobSubmission_GeneralTabName","sparkJobSubmission_JobNamePlaceHolder","sparkJobSubmission_JobName","sparkJobSubmission_SparkCluster","sparkJobSubmission_FilePathPlaceHolder","sparkJobSubmission_LocalFileDestinationHintWithPath","sparkJobSubmission_MainFilePath","sparkJobSubmission_MainClass","sparkJobSubmission_Arguments","sparkJobSubmission_ArgumentsTooltip","sparkJobSubmission_NotSpecifyJobName","sparkJobSubmission_NotSpecifyJARPYPath","sparkJobSubmission_NotSpecifyJARPYPath","sparkJobSubmission_NotSpecifyMainClass","sparkJobSubmission_HDFSFileNotExistedWithPath","sparkJobSubmission_HDFSFileNotExisted","sparkSelectLocalFile","sparkJobSubmission_SelectFileError"]},"sparkFeature/dialog/sparkJobSubmission/sparkAdvancedTab":{"messages":["ADVANCED","Reference Jars","Jars to be placed in executor working directory. The Jar path needs to be an HDFS Path. Multiple paths should be split by semicolon (;)","Reference py Files","Py Files to be placed in executor working directory. The file path needs to be an HDFS Path. Multiple paths should be split by semicolon(;)","Reference Files","Files to be placed in executor working directory. The file path needs to be an HDFS Path. Multiple paths should be split by semicolon(;)"],"keys":["sparkJobSubmission_AdvancedTabName","sparkJobSubmission_ReferenceJarList","sparkJobSubmission_ReferenceJarListToolTip","sparkJobSubmission_ReferencePyList","sparkJobSubmission_ReferencePyListTooltip","sparkJobSubmission_ReferenceFilesList","sparkJobSubmission_ReferenceFilesListTooltip"]},"sparkFeature/dialog/dialogCommands":{"messages":["Please select SQL Server with Big Data Cluster. ","No Sql Server is selected.","Error Get File Path: {0}"],"keys":["sparkJobSubmission_PleaseSelectSqlWithCluster","sparkJobSubmission_NoSqlSelected","sparkJobSubmission_GetFilePathFromSelectedNodeFailed"]},"sparkFeature/sparkUtils":{"messages":["... Creating {0}","Process exited with code {0}"],"keys":["mkdirOutputMsg","executeCommandProcessExited"]},"prompts/confirm":{"messages":["Yes","No"],"keys":["msgYes","msgNo"]},"objectExplorerNodeProvider/objectExplorerNodeProvider":{"messages":["Session for node {0} does not exist","Error notifying of node change: {0}","Root","HDFS","Data Services"],"keys":["sessionNotFound","notifyError","rootLabel","hdfsFolder","dataServicesLabel"]},"objectExplorerNodeProvider/hdfsProvider":{"messages":["Error: {0}","Cannot delete a connection. Only subfolders and files can be deleted."],"keys":["errorExpanding","errDeleteConnectionNode"]},"objectExplorerNodeProvider/hdfsCommands":{"messages":["All Files","Upload","Uploading files to HDFS","Upload operation was canceled","Error uploading files: {0}","Creating directory","Operation was canceled","Error uploading files: {0}","Enter directory name","Error deleting files {0}","Are you sure you want to delete this folder and its contents?","Are you sure you want to delete this file?","Saving HDFS Files","Save operation was canceled","Error saving file: {0}","Generating preview","Error previewing file: {0}","Error copying path: {0}"],"keys":["allFiles","lblUploadFiles","uploading","uploadCanceled","uploadError","makingDir","mkdirCanceled","uploadError","enterDirName","deleteError","msgDeleteFolder","msgDeleteFile","saving","saveCanceled","saveError","previewing","previewError","copyPathError"]},"objectExplorerNodeProvider/connection":{"messages":["ConnectionInfo is undefined.","ConnectionInfo.options is undefined.","Some missing properties in connectionInfo.options: {0}"],"keys":["connectionInfoUndefined","connectionInfoOptionsUndefined","connectionInfoOptionsMissingProperties"]},"objectExplorerNodeProvider/command":{"messages":["$(sync~spin) {0}...","Cancel","Cancel operation?"],"keys":["progress","cancelTooltip","cancel"]},"objectExplorerNodeProvider/cancelableStream":{"messages":["Stream operation canceled by the user"],"keys":["streamCanceled"]},"main":{"messages":["This sample code loads the file into a data frame and shows the first 10 results.","Notebooks","Only .ipynb Notebooks are supported"],"keys":["msgSampleCodeDataFrame","notebookFileType","unsupportedFileType"]},"localizedConstants":{"messages":["Node Command called without any node passed","Local file will be uploaded to HDFS. ",".......................... Submit Spark Job End ............................","Uploading file from local {0} to HDFS folder: {1}","Upload file to cluster Succeeded!","Upload file to cluster Failed. {0}","Submitting job {0} ... ","The Spark Job has been submitted.","Spark Job Submission Failed. {0} ","YarnUI Url: {0} ","Spark History Url: {0} ","Get Application Id Failed. {0}","Local file {0} does not existed. ","No Sql Server Big Data Cluster found."],"keys":["msgMissingNodeContext","sparkJobSubmission_LocalFileDestinationHint","sparkJobSubmission_SubmissionEndMessage","sparkJobSubmission_PrepareUploadingFile","sparkJobSubmission_UploadingFileSucceeded","sparkJobSubmission_UploadingFileFailed","sparkJobSubmission_PrepareSubmitJob","sparkJobSubmission_SubmitJobFinished","sparkJobSubmission_SubmitJobFailed","sparkJobSubmission_YarnUIMessage","sparkJobSubmission_SparkHistoryLinkMessage","sparkJobSubmission_GetApplicationIdFailed","sparkJobSubmission_LocalFileNotExisted","sparkJobSubmission_NoSqlBigDataClusterFound"]}}